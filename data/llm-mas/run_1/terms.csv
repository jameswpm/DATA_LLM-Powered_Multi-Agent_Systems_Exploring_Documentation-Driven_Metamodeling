Term,Definition,# of mentions in the frameworks
Agent,"An autonomous software entity that can perform tasks independently or collaboratively with other agents. Agents perceive their environment, maintain internal state, and take actions based on instructions or goals.",44
Vector Database,A specialized database that stores high-dimensional embeddings for semantic similarity search. Vector databases enable agents to retrieve relevant information based on meaning rather than exact keyword matches.,36
Workflow,"A deterministic sequence of steps defining a process or execution path for agents. Workflows orchestrate multiple operations, tools, or agent interactions to accomplish complex tasks, including integrating multiple LLMs into their processes.",36
Tool,"A utility or function that an agent can invoke to perform specific operations. Tools are often external APIs, database queries, or computational functions that extend the agent's capabilities beyond language generation.",33
Memory,"The mechanism by which an agent stores and retrieves information across interactions. Memory systems handle conversation history, learned facts, and contextual knowledge to enable stateful behavior.",32
Task,"A specific goal or objective that an agent is designed to accomplish, such as answering questions, generating text, or completing a task. Tasks can be defined using natural language instructions or through more formalized APIs and interfaces.",9
Session,"A period of interaction between a user and an agent, during which the agent provides responses to user input and updates its internal state accordingly. Sessions can be used to track conversation history, maintain context, and improve overall user experience.",7
RAG,A Retrieval-Augmented Generation model that combines the strengths of both retrieval and generation to produce high-quality output. RAG models retrieve relevant information from a database or knowledge graph and use it to inform their generated text.,7
Context,"The surrounding information and circumstances that influence an agent's behavior and decision-making processes. Context can include conversation history, user preferences, environmental factors, or other relevant details that impact the agent's performance and accuracy.",7
Prompt,"A piece of text that is input into an agent or model, often serving as the starting point for generating output. Prompts can be used to specify task objectives, provide context, or guide the generation process in various ways.",7
Team,"A collection of agents working together to achieve a common goal or complete a complex task. Teams in the Upsonic Framework enable collaboration between multiple agents, allowing for more sophisticated and efficient problem-solving.",6
Model,"A software component that generates output based on input data, often using machine learning algorithms or statistical models. Models can be used for language generation, classification, regression, or other tasks, and are a key component of many AI agents.",6
Agent Framework,"A software framework that provides a set of tools and abstractions for building and deploying agent-based systems. Agent frameworks often include features such as state management, memory, and human-in-the-loop review.",5
State,"The current status or condition of an agent's internal workings, including memory, knowledge, and other relevant factors that influence its behavior. State is essential for maintaining consistency and coherence in the agent's interactions with users and external systems.",5
LLM (Large Language Model),A type of artificial intelligence model that is trained on large amounts of text data to generate human-like responses. LLMs are used in KaibanJS to provide specialized AI capabilities for tasks such as language generation and processing.,4
Plugin,"A modular component that extends the functionality of the kernel or provides additional services to agents. Plugins can be used to integrate external libraries, APIs, or data sources into the kernel.",3
RAG (Retrieval-Augmented Generation),A context-augmentation technique that combines context with LLMs at inference time. RAG enables agents to retrieve relevant information based on meaning rather than exact keyword matches.,3
Hub,A community repository of data loaders and integration tools that enable agents to connect to various data sources and integrate with different systems. Hub simplifies the process of integrating new data sources and tools into LlamaIndex applications.,3
Multi-Agent System,"A system comprising multiple autonomous agents that interact with each other to achieve common goals or objectives. Multi-agent systems enable distributed problem-solving, coordination, and cooperation among agents.",3
CrewAI,"A collaborative AI agent framework aimed at strengthening teamwork by facilitating communication through AI-driven insights, promoting more effective collaboration and decision-making in group settings.",2
LLM,"Large Language Model, a type of artificial intelligence model that uses deep learning techniques to process and generate human-like language. LLMs are trained on vast amounts of text data and can perform tasks such as language translation, text summarization, and question answering.",2
Semantic Kernel,"A natural language processing (NLP) component that enables agents to comprehend user intentions by analyzing context, syntax, and semantics of input text, facilitating more accurate understanding and response.",2
Flow,"An advanced orchestration mechanism that enables complex workflows with state management. Flows allow for dynamic routing, parallel execution, and human-in-the-loop review to create sophisticated multi-agent systems.",2
LlamaIndex,"A framework for building and orchestrating multi-agent AI systems, including RAGs. LlamaIndex provides a standardized protocol for connecting data sources and integrating tools to enable complex operations and workflows.",2
Guardrail,"A guardrail is a mechanism that applies rules or transformations to inputs and outputs of an agent to ensure security, compliance, or quality standards.",2
Action,"A step in a workflow that sends data to external services, such as Discord or Slack, based on the output of an AI agent.",2
MCP,"A framework for building and managing AI agents, providing a structured approach to developing and deploying intelligent software entities. MCP is the core architecture of Mastra's agent development platform.",2
Qdrant,"A vector database used in the example notebook for efficient semantic similarity search and knowledge retrieval by Camel-AI agents, enabling them to access relevant information based on meaning rather than exact keyword matches.",2
Crew,A group of AI agents that collaborate via context sharing and delegation to perform complex tasks. Crews are managed by a planning agent and can be composed of multiple task-specific agents.,2
Mastra,"A platform for building and deploying AI agents, providing a comprehensive suite of tools and features for developing, testing, and deploying intelligent software entities. Mastra is an open-source platform under the Apache 2.0 license.",2
OpenAPI Specification,"A standardized way of describing APIs, used for importing plugins from external sources and sharing them across different programming languages and platforms.",2
Intent,"A representation of a user's goal or objective, extracted from their input using natural language processing techniques. Intents are used to determine the user's intent behind their message and trigger corresponding actions within an agent's state machine.",1
Event,"A notification or update that triggers an action or transition within an agent's state machine. Events are used to manage the flow of conversations, track changes in the conversation context, and trigger actions based on specific conditions.",1
Platform,"A framework for deploying and managing agent instances, providing a platform-agnostic interface for interacting with agents. Platforms enable the deployment of agents in various environments and facilitate communication between agents and external systems.",1
MonitoringDB,"A database used for monitoring agent sessions, storing information about chat history, events, and other relevant data points to facilitate analysis and optimization of the agent's performance.",1
NLPEngine,"The natural language processing engine responsible for tasks such as text analysis, entity recognition, and intent classification. It integrates various NLP components to provide a comprehensive solution.",1
IntentClassifierConfiguration,"A configuration object used to customize the behavior of intent classifiers, including settings for LLMs and other parameters that influence prediction accuracy.",1
MPT-30B-Chat,"A chatbot-like model for dialogue generation that was built by fine-tuning MPT-30B and trained on 19.54% Camel-AI sourced data. MPT-30B-Chat is designed to generate human-like conversations and can be used in various applications, such as customer service or chatbots.",1
OpenHermes,"A model that was trained on the CAMEL AI 'Domain Expert' dataset, comprising 25,000 conversations between two GPT 3.5 Turbo agents. OpenHermes is designed to generate human-like conversations and can be used in various applications, such as customer service or chatbots.",1
Firecrawl,"An external service or tool that agents can interact with to perform specific operations, such as data retrieval or processing, extending the agent's capabilities beyond language generation.",1
Qwen Model,"A type of large language model (LLM) optimized for efficiency and performance, used in the example notebook to demonstrate Camel-AI's capabilities with SambaCloud as the serving platform.",1
SambaCloud API,"An external API providing access to SambaNova's cloud-based AI infrastructure, enabling Camel-AI agents to leverage scalable and secure AI capabilities.",1
Harm Prevention,A mechanism for preventing agents from causing harm or engaging in malicious behavior during conversations. Harm prevention is used in multi-agent systems like CAMEL-AI to ensure safe and responsible AI interactions.,1
Role Assignment,"The process of defining roles for agents in a conversation, such as assigning one agent to play the role of customer service representative and another to play the role of customer. Role assignment is used in multi-agent systems like CAMEL-AI to ensure consistent and effective dialogue.",1
Fine-Tuning,"The process of adjusting a pre-trained AI model to fit specific tasks or applications. Fine-tuning involves retraining the model on a smaller dataset, often with additional training data or custom objectives, to improve its performance and adapt it to new use cases.",1
GitHub,"A web-based platform for version control and collaboration on software development projects. The GitHub agent uses this platform to interact with repositories, manage code, and collaborate with developers.",1
Entity,"A specific concept or object mentioned in a conversation, such as a person, location, or organization. Entities are used to track and manage relevant information about the conversation context and enable agents to provide more accurate and informative responses.",1
Phi,"A model that was trained on the CAMEL AI 'Domain Expert' dataset, comprising 25,000 conversations between two GPT 3.5 Turbo agents. Phi is designed to generate human-like conversations and can be used in various applications, such as customer service or chatbots.",1
Synthetic Data,"Data that is generated artificially using AI models, such as CAMEL-AI's Domain Expert dataset. Synthetic data can be used to train and fine-tune AI models, reducing the need for real-world data and improving model performance.",1
Transition,"A change in an agent's state machine, triggered by specific events or conditions. Transitions enable agents to adapt their behavior based on changes in the conversation context and facilitate a more dynamic and responsive interaction experience.",1
Domain Expert,"A dataset of conversations between two agents that has been curated to demonstrate specific behaviors, such as role assignment, harm prevention, and consistent conversation. Domain experts are used for training and fine-tuning AI models.",1
Prompt Engineering,"The process of designing and refining prompts to elicit specific responses from agents or to achieve particular goals in conversations. Prompt engineering involves careful definition of roles, constraints, and objectives to ensure consistent and effective dialogue.",1
Inception Prompting,"A type of prompt engineering that involves defining the initial context and objectives for a conversation between two agents. Inception prompting is used in multi-agent systems like CAMEL-AI to assign roles, prevent harm, and encourage consistent conversation.",1
Chain,A lightweight and extensible generative agent pipeline that enables developers to build customized conversational agents using large language models (LLMs) with custom tools and automatically evaluate different user scenarios with simulated conversations.,1
GitLab,"A web-based platform for version control and collaboration on software development projects. The GitLab agent uses this platform to interact with repositories, manage code, and collaborate with developers.",1
Langchain,"An AI agent framework specializing in leveraging various APIs to ensure agents can access and utilize external data effectively, enhancing the breadth of knowledge and capabilities within intelligent systems.",1
Promptflow,"A tool for developers to create conversational agents that can navigate complex interactions seamlessly, leveraging a structured approach to prompt design and execution.",1
Autogen,"An AI agent framework designed to streamline the development of AI agents through automation of code generation, enabling rapid prototyping and deployment of intelligent systems.",1
Factory (Self-hosted),"A containerized deployment option for CrewAI, allowing teams to host the framework on their own infrastructure, with support for hyperscalers and on-prem deployments.",1
Delegation,The process of assigning tasks to specific AI agents within a crew based on their capabilities and expertise. Delegation enables efficient task allocation and execution.,1
Azure Model,"An integration with Azure OpenAI services, allowing agents to access pre-trained models and fine-tune them for specific tasks. This integration enables seamless deployment of AI-powered applications on the Azure platform.",1
LangGraph,"A framework integration that enables agents to leverage external knowledge graphs and semantic networks. LangGraph provides a structured representation of domain-specific concepts and relationships, enhancing agent reasoning and decision-making capabilities.",1
MemGPT,"An AI agent architecture combining memory-optimized architectures with generative capabilities, allowing for more personalized interactions with users by leveraging contextual knowledge and adapting to user preferences.",1
Modular,"A design approach that breaks down complex systems into smaller, independent components or modules. Modular architecture allows for easier maintenance, updates, and extensions of the system.",1
LMOS Protocol,"The standardized communication protocol for establishing a distributed, open ecosystem of AI agents and tools. The LMOS Protocol ensures interoperability across diverse agent platforms and domains.",1
Agent & Tool Description Format,A standardized format for describing the capabilities and metadata of Agents and Tools using JSON-LD. This specification facilitates interoperability across diverse agent platforms and domains.,1
Metadata Propagation Protocol,"The mechanism by which agents and tools propagate metadata, supporting both local network discovery and registration, as well as broader network discovery through Agent registries or decentralized protocols.",1
Agent & Tool Discovery Process,"A discovery mechanism for obtaining agent and tool descriptions, accommodating updates to descriptions and handling the dynamic nature of agents. Agents can query centralized registries based on specific criteria, ensuring the right Agents or Tools are matched for a given task.",1
NVIDIA Models,"A set of pre-trained models developed by NVIDIA's AI ecosystem, optimized for various tasks such as natural language processing, computer vision, and recommendation systems. Agents can leverage these models to enhance their performance and accuracy.",1
Kubernetes,"An open-source container orchestration system for automating the deployment, scaling, and management of containers across clusters. Kubernetes is used in LMOS to manage multi-agent systems.",1
Cloud-Native,"A software architecture designed to take advantage of cloud computing resources, such as scalability, on-demand provisioning, and high availability. Cloud-native applications are built to run efficiently in a cloud environment.",1
Agent ReaCtor (ARC),"A framework provided by LMOS to abstract the intricacies of large language models (LLMs), memory management, and tool integration. ARC acts as a virtual 'OS' for AI agents, allowing developers to focus on creating intelligent, adaptable agents without getting bogged down by infrastructure complexity.",1
"Open, Interoperable Architecture","The architecture of LMOS that supports seamless integration of AI agents across diverse platforms and networks. By embracing open standards, LMOS ensures that agents from various platforms can communicate, share knowledge, and collaborate, fostering innovation across industries.",1
Agent Lifecycle Management,"The feature provided by LMOS to enable real-world deployment strategies, such as canary releases and advanced routing techniques based on Natural Language Understanding (NLU). This allows enterprises to introduce new agent features incrementally, ensuring stability and reducing risk during updates.",1
Cloud-Native Scalability,"The scalability feature of LMOS that leverages Kubernetes to ensure cloud-native scalability. AI agents can grow alongside business needs, whether managing a small number of agents or deploying hundreds across multiple channels (e.g., web, mobile, IVR).",1
Collaborative Agent Ecosystem,"The collaborative approach enabled by LMOS that allows AI agents to share tools, memory, and knowledge much like applications in a traditional operating system. This enhances adaptability, allowing agents to handle complex queries and deliver more accurate, comprehensive solutions.",1
Intelligent Task Management,"The feature of LMOS that utilizes both language model-based approaches and other mechanisms to manage tasks efficiently. This enables AI agents to handle complex queries and deliver more accurate, comprehensive solutions.",1
Agent Definition Language (ADL),A simple yet powerful language to enable the definition of an AI Agent's behavior more reliably and efficiently.,1
Tracing Framework,"A system for monitoring and analyzing the performance of agents, including tracing frameworks such as Arize Phoenix, Zipkin, Wavefront, or OTLP.",1
MCP (Multi-Client Protocol),"A protocol that enables multiple clients to communicate with a single server, used by the Arc Framework for client-server communication.",1
Spring Boot Starter,A project template and set of dependencies that simplify the integration of the Arc Framework into Spring Boot applications.,1
LangChain4j,"The underlying library used by the Arc Framework for building and managing AI agents, providing a foundation for agent creation and interaction.",1
Workflow Agent,"A specialized agent responsible for defining and executing workflows using workflow agents (Sequential, Parallel, Loop) for predictable pipelines, or leveraging LLM-driven dynamic routing (LlmAgent transfer) for adaptive behavior.",1
LLM-Agent,An agent that leverages large language models to enable dynamic routing and adaptive behavior in workflows. It uses the capabilities of pre-trained language models to make decisions and take actions.,1
Decentralized Digital Identifiers,"W3C Decentralized Identifiers (DIDs) used by agents and tools for secure, verifiable, and self-sovereign authentication. This ensures cryptographic identity validation without relying on centralized authorities, enhancing trust, security, and interoperability across networks.",1
Agent Communication Protocol,"The open protocol used by agents to communicate with each other, allowing flexibility in choosing the best transport protocol for each agent's purpose. Agents can select and adapt protocols based on their needs.",1
Group Management,"The functionality provided by LMOS to create and manage agent groups, enforcing trust relationships among agents within the group. This enhances collaboration and coordination across agents in the system.",1
Loop Workflow Agent,"A workflow agent that repeats a set of tasks until a certain condition is met, allowing for flexible and dynamic workflows.",1
Parallel Workflow Agent,"A workflow agent that executes multiple tasks concurrently, enabling faster execution times and improved performance.",1
Sequential Workflow Agent,"A workflow agent that executes tasks in a sequential order, allowing for predictable pipelines and easy debugging.",1
Agent Registry,"A centralized repository for registering, managing, and tracking agent instances. The registry facilitates agent discovery, deployment, and monitoring across the system.",1
Callback,"A mechanism for an agent to notify another entity (e.g., user, system, or other agent) about the completion of a task or the occurrence of an event. Callbacks facilitate asynchronous communication and enable agents to coordinate actions.",1
Artifacts,"The output or results produced by an agent's processing or computation. Artifacts can be text, images, audio, or other forms of data that are generated during the execution of tasks or workflows.",1
Events,"Notifiable occurrences or changes within an agent or system that trigger reactions or responses from other agents or entities. Events enable agents to react to external stimuli, adapt to changing circumstances, and maintain situational awareness.",1
LlmAgent Transfer,"A mechanism that enables LLM-agents to transfer knowledge and adapt to new contexts, enabling adaptive behavior in workflows.",1
Plugins,"Customizable extensions or add-ons to an agent's core functionality. Plugins enable developers to extend the capabilities of agents, adapt to changing requirements, and create tailored solutions for specific use cases.",1
APIHubToolset,A utility for turning documented APIs from Apigee API Hub into tools with a few lines of code. This toolset enables the creation of agent tools by leveraging OpenAPI specs from Apigee API Hub.,1
Authentication,"The process of verifying an agent's identity and granting access to APIs or other resources. ADK supports token-based auth (API Key, Bearer token), service account, and OpenID Connect for secure authentication.",1
Agent Definition,"A file (e.g., Agent.py) that defines an agent's behavior, including the tools it can use and the workflows it can execute. The agent definition is used by ADK to create a functional agent instance.",1
APIHub Resource,An OpenAPI spec from Apigee API Hub that defines an API's structure and behavior. Agents can use these resources to interact with APIs and perform tasks.,1
Hugging Face MCP Server,A server that connects your ADK agent to the Hugging Face Hub and thousands of Gradio AI Applications.,1
Hugging Face Hub,"A platform providing access to thousands of Gradio AI Applications and a repository of models, datasets, and papers that can be searched and filtered based on tasks, libraries, or keywords.",1
Apps,"Reusable software components or modules that encapsulate specific functionality or services. Apps can be integrated into agent workflows, providing a modular and extensible architecture for building complex systems.",1
Gradio Spaces,"Pre-built AI applications that can perform specific tasks, such as background removal or text-to-speech, which can be discovered and used by agents through the Hugging Face Hub.",1
MCP Toolset,"A collection of tools and utilities provided by the MCP Server for interacting with the Hugging Face Hub and Gradio AI Applications, including search and filtering capabilities.",1
Transport Type,"The method used for communication between the agent and the MCP Server, which can be stdio, sse, streamableHttp, or streamableHttpJson.",1
DEFAULT_HF_TOKEN,"An environment variable that specifies a default Hugging Face token to use if no header is sent in requests, intended for development/test environments or local STDIO deployments.",1
Kaiban Board,"A visual representation of the workflow and its components, providing a clear overview of the task flow and enabling real-time collaboration between humans and AI agents.",1
Role-Based Agent Design,"An approach to designing agents where each agent has a specific role or function within the workflow, enabling specialization and enhancing the effectiveness of each task.",1
Planning Agent,"An AI agent responsible for creating step-by-step plans for tasks, which it shares with the crew. Planning agents enable coordinated action among team members.",1
Agentic RAG,"A knowledge retrieval system combining a broad range of sources, including files, websites, and vector databases, with intelligent query rewriting for optimized retrieval.",1
Context Sharing,"A mechanism by which AI agents share information about their environment, goals, or state with other agents in the crew. Context sharing enables coordinated action among team members.",1
Reasoning,"The ability of an AI agent to reflect on its current task objective, create and refine a structured plan to execute it, and inject the plan into the task description.",1
AMP (SaaS),"A cloud-based deployment option for CrewAI, offering zero installation requirements, automatic updates, and managed infrastructure and scaling.",1
ConversationalAgent,"An agent that can engage in multi-turn conversations with users, leveraging LLMs for text generation and responding to user inputs. Conversational agents maintain context and adapt to user queries.",1
OpenAIFunctionsAgent,"An agent that leverages OpenAI models and supports function calling, enabling users to interact with LLMs in a more direct manner. OpenAIFunctionsAgents can perform complex tasks by invoking OpenAI functions.",1
BufferMemory,"A simple memory tracking system for conversation history and tools' outputs, allowing agents to maintain context and recall previous interactions.",1
WorkflowEvaluation,"A framework for evaluating generative agents' performance under different user scenarios. Workflow evaluations involve simulated conversations between the agent and LLM-simulated test users, enabling easy addition of test cases for new user scenarios and fast evaluation.",1
Telegram,A messaging platform used by the Telegram agent to interact with users and perform tasks such as sending messages and receiving updates.,1
LLM (Language Model),"A specialized AI model expertly tailored to excel in distinct aspects of projects, such as text generation, translation, or question-answering. LLMs are integrated into agents to optimize AI solutions for accurate and efficient outcomes.",1
workflowLogs,"Records all significant events and changes in the workflow's status, invaluable for debugging, auditing, and understanding the sequence of operations within the store.",1
workflowContext,"A deprecated attribute that stored essential context or metadata from the workflow execution, now dynamically derived from the workflowLogs array.",1
tasks,"Contains all tasks assigned to the team, each managed according to the workflow defined by the team's operational rules.",1
agents,"An array listing the agents involved in the team, detailing their roles and responsibilities within the workflow and current status.",1
workflowResult,"Stores the final result or output of the workflow once it has completed, particularly useful for retrieving the outcome of all tasks processing.",1
Workflow Status,"An attribute indicating the current state of the team's workflow process, transitioning through various statuses reflecting different phases of the workflow lifecycle.",1
State Management,"The method by which software keeps track of changes in an application's state over time, ensuring predictable responses to user inputs and internal changes.",1
Team Store,"A specialized component in KaibanJS that manages the state and workflows of agents and tasks within a team, ensuring seamless operation and efficient data flow.",1
LLM-Friendly Documentation,"Documentation formatted in a way that's optimized for large language models (LLMs) and can be easily integrated with AI coding assistants, IDEs, or LLM tools.",1
ToolMessage,A type of message that an agent can send to an LLM to invoke a specific tool or function. ToolMessages are used to extend the agent's capabilities beyond language generation.,1
OpenAI Tool Call,"A specific type of tool call made by an agent to an OpenAI API. OpenAI tool calls enable agents to access external APIs and services, such as text generation or image processing.",1
Chroma,A vector-store library supported by Langroid for storing and retrieving high-dimensional embeddings.,1
Model Provider,"A service that offers access to various language models (LLMs), enabling developers to integrate multiple models into their projects. Model providers manage API keys, model selection, and configuration for seamless integration with agents.",1
Workflows,"An event-driven, async-first workflow engine that orchestrates multi-step AI processes, agents, and document pipelines with precision and control.",1
LlamaCloud,"A cloud-based platform that powers enterprise-grade document automation with industry-best parsing, extraction, indexing, and retrieval — optimized for accuracy, configurability, and scalability.",1
Context Augmentation,"The process of making data available to LLMs to solve problems at hand. Context augmentation involves ingesting, parsing, indexing, and processing data to enable stateful behavior in agents.",1
Schema-Based Extraction,A method for extracting structured information from documents based on predefined schemas or templates. Schema-based extraction enables agents to extract relevant data points with high accuracy and precision.,1
Document Parsing,"The process of extracting structured information from unstructured documents. Document parsing involves identifying and extracting relevant data points, such as tables, images, and text, from complex layouts and formats.",1
Workflow Engine,"A system that manages the execution of workflows, including tasks, agents, and document pipelines. Workflow engines provide a flexible way to orchestrate complex AI processes.",1
Engines,"Natural language interfaces that provide access to data, enabling agents to query and retrieve relevant information. Engines include query engines, chat engines, and agents, each with its own capabilities and use cases.",1
Observability/Evaluation Integrations,"Tools that enable rigorous experimentation, evaluation, and monitoring of AI agent applications. These integrations facilitate a virtuous cycle of improvement and refinement in agent development.",1
Data Indexes,Mechanisms that structure data in intermediate representations easy for LLMs to consume. Data indexes enable efficient querying and retrieval of relevant information from large datasets.,1
Data Connectors,"Tools that ingest existing data from its native source and format, making it available for LLMs to consume. Data connectors handle various data types, including APIs, PDFs, SQL databases, and more.",1
semtools,"A semantic analysis toolkit that provides advanced text understanding and processing capabilities. semtools enables agents to analyze and reason about complex texts, including documents, articles, and books.",1
Vibe-llama,"A multimodal RAG framework for processing videos, images, and audio. Vibe-llama enables agents to understand and interact with multimedia content in a more comprehensive and accurate manner.",1
Create Llama,"A CLI tool for quickly scaffolding new LlamaIndex applications. Create Llama provides a streamlined process for building and deploying multi-agent systems, reducing development time and effort.",1
Evals,"Evaluation methods used to assess the performance and accuracy of AI agents. Evals in Mastra include model-graded, rule-based, and statistical methods for evaluating agent output.",1
Scorer,"An automated test that evaluates AI outputs using model-graded, rule-based, and statistical methods. Scorers return scores quantifying how well an output meets evaluation criteria.",1
LanceDB,A vector-store library supported by Langroid for storing and retrieving high-dimensional embeddings.,1
Vector-Store,A specialized database that stores high-dimensional embeddings for semantic similarity search. Vector-stores enable agents to retrieve relevant information based on meaning rather than exact keyword matches.,1
llmConfig,"A configuration object used to specify the LLM provider, model, and API key for each agent. This configuration enables agents to utilize specific models tailored to their tasks and goals.",1
Prompt Engineering Scorer,A type of scorer used to explore the impact of different instructions and input formats on agent outputs.,1
Classification Scorer,A type of scorer that measures accuracy in categorizing data based on predefined categories.,1
Textual Scorer,"A type of scorer that evaluates accuracy, reliability, and context understanding of agent responses.",1
Live Evaluation,"An asynchronous process where scorers run in the background, evaluating AI outputs in real-time without blocking agent responses or workflow execution.",1
Observability,The process of collecting trace data to enable scoring of historical traces. Requires configuration in your Mastra instance.,1
Processor,"A utility or function that an agent can invoke to perform specific operations, such as input and output processing.",1
Automatic Storage,The process where all scoring results are automatically stored in the mastra_scorers table in your configured database for analysis and performance tracking over time.,1
Sampling Control,"A parameter (0-1) that controls what percentage of outputs get scored. A value of 1 scores every single response, while a value of 0 disables scoring.",1
Output Processor,"An output processor is applied after the language model generates a response but before it is returned to the user. It's useful for response optimization, moderation, transformation, and applying safety controls.",1
Moderation Processor,A moderation processor is an input processor that detects and flags inappropriate content in user messages based on predefined categories and thresholds.,1
Prompt Injection Detector,"A prompt injection detector is an input processor that scans user messages for prompt injection, jailbreak attempts, and system override patterns to prevent malicious activity.",1
Language Detector,A language detector is an input processor that detects the language of user messages and translates them into a target language if necessary.,1
Batch Parts Processor,"A batch parts processor is an output processor that combines multiple stream parts before emitting them to the client, reducing network overhead and improving the user experience.",1
Token Limiter Processor,A token limiter processor is an output processor that limits the number of tokens in model responses to manage cost and performance by truncating or blocking messages when the limit is exceeded.,1
Input Processor,"An input processor is applied before user messages reach the language model. It's useful for normalization, validation, content moderation, prompt injection detection, and security checks.",1
Trace Evaluation,"A method of evaluating historical traces from agent interactions and workflows, useful for analyzing past performance, debugging issues, or running batch evaluations.",1
AI SDK UI,"A user interface component library for building interactive chat experiences, providing tools for rendering conversation history, prompts, and responses in a visually appealing manner.",1
System Prompt Scrubber,A system prompt scrubber is an output processor that detects and redacts system prompts or other internal instructions from model responses to prevent unintended disclosure of prompt content or configuration details.,1
ToolUIPart,"A UI component representing a tool or function invoked by an agent to perform specific operations, displaying input fields, output results, and error messages as needed.",1
AI Elements,"A set of reusable UI components for building conversational interfaces, including tools for displaying conversation history, prompts, and responses, as well as input fields for user interaction.",1
Role,A specific function or responsibility assigned to an agent within a multi-agent system. Roles define the tasks and interactions each agent is expected to perform.,1
SELA,"The core framework for building and managing AI agent systems, providing a structured approach to developing autonomous software entities.",1
Datasets,"Collections of data used to train, evaluate, or fine-tune agents. Datasets can be pre-existing or generated on-the-fly by the agent.",1
DefaultChatTransport,"A transport mechanism for handling chat interactions between the client and server, enabling the streaming of agent responses in AI SDK format.",1
Task Decomposition,"The process of breaking down complex tasks into smaller, manageable sub-tasks that can be executed by individual agents or workflows.",1
Graph,"A data structure representing the LLM workflow as a network of nodes and edges, enabling the modeling of complex interactions between agents and tasks.",1
Shared Store,"A mechanism that enables communication between nodes within flows, allowing agents to share information and coordinate their actions.",1
Node,"A basic unit in the graph abstraction, representing a simple task or operation that can be executed by an agent.",1
Batch Node/Flow,"A type of node or flow that allows for data-intensive tasks to be executed efficiently, enabling agents to process large amounts of data.",1
Async Node/Flow,"A type of node or flow that enables waiting for asynchronous tasks to complete, allowing agents to execute tasks concurrently and improve overall efficiency.",1
ChatDocument,"A data structure representing a conversation or message exchange between an agent and its environment. ChatDocuments contain metadata about the interaction, such as the sender, recipient, and content.",1
Redis,A caching system used by Langroid to store and retrieve cached LLM prompts and responses.,1
Tool Call Tracking,The mechanism by which the CLI displays which tools were called during agent execution.,1
Parallel Node/Flow,"A type of node or flow that handles I/O-bound tasks efficiently, enabling agents to perform multiple tasks simultaneously and improve overall throughput.",1
Autonomy Modes,"Control AI autonomy: suggest, auto_edit, full_auto. Autonomy modes determine how agents interact with their environment and make decisions.",1
Cost Tracking,Real-time token usage and cost monitoring. Cost tracking enables developers to monitor the financial implications of agent execution.,1
Message Queue,Queue messages while agent is processing. Message queues enable agents to handle multiple tasks concurrently and manage communication between components.,1
Git Integration,"Auto-commit with AI messages, diff viewing. Git integration enables agents to interact with version control systems and collaborate on code development.",1
Repository Map,Intelligent codebase mapping with tree-sitter. Repository maps enable agents to understand project structure and navigate codebases more effectively.,1
Interactive TUI,Rich terminal interface with completions. Interactive TUIs provide a user-friendly interface for interacting with agents and their outputs.,1
Claude Memory,Anthropic’s memory tool integration. Claude Memory enables agents to access and manage knowledge bases using Anthropic's memory tool.,1
Planning & Memory,"Enable planning mode, tools for planning phase, chain-of-thought in planning, auto-approve generated plans, file-based memory, auto extract memories, Claude Memory Tool (Anthropic only). Planning and memory enable agents to plan and execute tasks more effectively.",1
Tools & Extensions,"Load additional tools, use MCP server, MCP environment variables, agent delegation, final agent for multi-agent tasks. Tools and extensions provide a way to customize and extend agent capabilities.",1
Web & Search,"Enable native web search, enable web fetch for URLs, run deep research on topic, rewrite query for better results. Web and search enable agents to interact with the internet and retrieve information more effectively.",1
Context & Prompts,"Add code context from path, read input from file, repository URL for context, goal for context engineering, automatic analysis, expand short prompt to detailed. Context and prompts enable agents to understand project structure and generate more effective prompts.",1
Monitoring & Display,"Real-time token usage and cost monitoring, maximum tokens for response, load history from last N sessions, display agent panels with verbose output. Monitoring and display provide a way to track agent performance and interact with their outputs.",1
Sandbox Execution,Secure isolated command execution. Sandbox execution provides a safe environment for testing and executing agent tasks without compromising the host system.,1
All CLI Features,"Deep Research, Automated multi-step research with citations. All CLI features provide a comprehensive set of tools for building and interacting with agents.",1
SupportDependencies,"A data class representing the dependencies required by a support agent, including customer ID and database connection.",1
RunContext,"A data structure containing the context and dependencies required for an agent's execution, including input parameters, tool configurations, and output types.",1
ToolApproval,"A mechanism allowing agents to flag tool calls that require human approval before execution, based on conversation history, user preferences, or other factors.",1
SupportOutput,"A data model defining the structure of the output generated by a support agent, including advice, block card status, and risk level.",1
DurableExecution,"A feature enabling agents to preserve their progress across transient API failures and application errors or restarts, ensuring production-grade reliability for long-running workflows.",1
Function,"A unit of code within a plugin that performs a specific operation, often with semantic descriptions describing its input, output, and side effects.",1
Semantic Description,"A detailed description of how a function behaves, including its input, output, and side effects, used by the AI to understand and call the function correctly.",1
KernelFunction,"An attribute that annotates methods within a plugin class, indicating to Semantic Kernel that these functions can be called by an AI or referenced in a prompt.",1
MCP Server,"A server that hosts a collection of plugins, allowing other applications to consume these plugins as a service and access their functionality.",1
RAG (Retrieval Augmented Generation),"A technique used in retrieval functions, where data is retrieved from external sources and then used for generation tasks, often with strategies to improve performance such as caching and using cheaper intermediate models.",1
Task Automation,"The process of automating tasks within an application, often involving human-in-the-loop approval processes to ensure that tasks are completed correctly.",1
Kernel,"The core component of the Semantic Kernel framework, responsible for managing agent interactions, executing tasks, and providing services to agents. The kernel acts as a central hub for agent communication and coordination.",1
Service,"A reusable function or module that provides specific capabilities or functionality to agents within the kernel. Services can be used to perform tasks such as chat completion, planning, or data retrieval.",1
ChatCompletion,A service provided by the kernel for generating human-like responses to user input. Chat completion services use AI models to generate text based on context and conversation history.,1
Planning,"The process of generating a sequence of actions or steps to achieve a specific goal or objective. Planning is facilitated by the kernel through the use of planning services, which utilize AI models to generate plans based on context and constraints.",1
ChatHistory,"A data structure used by the kernel to store and manage conversation history between agents and users. Chat history enables agents to recall previous conversations, maintain state, and provide personalized responses.",1
CodeAgent,"A type of agent that writes its actions as Python code snippets, allowing for more efficient and secure execution.",1
ToolCallingAgent,"A standard agent that writes actions as JSON/text blobs, providing a sandboxed environment using Blaxel, E2B, or Docker.",1
LiteLLMModel,"A model that provides access to 100+ LLMs, enabling agents to use a wide range of language models without requiring extensive configuration or setup.",1
InferenceClientModel,"A gateway for all inference providers supported on HF, allowing agents to interact with various models and services through a unified interface.",1
Code Agent,"A type of agent that writes its actions in code to invoke tools or perform computations, enabling natural composability (function nesting, loops, conditionals).",1
Tool Calling Agent,An agent that supports usual JSON/text-based tool-calling for scenarios where that paradigm is preferred.,1
Inference Client Model,A specific type of model that uses the Hugging Face Inference API to interact with an agent.,1
Lite LLM Model,"A lightweight version of a large language model (LLM) that can be used with agents, accessed via APIs such as OpenAI or Anthropic.",1
Transformers Model,"A type of model that uses the Transformers library to interact with an agent, allowing for local model execution.",1
DuckDuckGo Search Tool,A tool that allows agents to search the web using DuckDuckGo's API.,1
Modal,"A sandboxed environment for executing code, providing a secure way to run agents and tools.",1
Blaxel,"A sandboxed environment for executing code, providing a secure way to run agents and tools.",1
E2B,"A sandboxed environment for executing code, providing a secure way to run agents and tools.",1
Docker,A containerization platform that allows agents and tools to be executed in isolated environments.,1
Model Context Protocol (MCP),A standardized interface allowing agents to interact with external tools and access real-world data beyond their language capabilities through STDIO or SSE MCP servers.,1
STDIO MCP Server,"A command-line tool implementing the MCP protocol, enabling agents to connect and perform actions using standardized interfaces.",1
SSE MCP Server,"A web-based MCP server using Server-Sent Events, allowing agents to interact with external tools through a standardized interface for real-world data access.",1
uAgents,A library developed by Fetch.ai for creating autonomous AI agents in Python. uAgents provides a simple and expressive way to create agents that can perform various tasks on a schedule or take action on events.,1
Almanac,"A smart contract deployed on the Fetch.ai blockchain, used by agents to register and join the network of uAgents. The Almanac enables secure registration and identity management for agents.",1
Agent Marketplace,"A platform where agents can be created, managed, and integrated with the Fetch.ai ecosystem. The Agent Marketplace enables developers to build and deploy their own agents using uAgents.",1
AgentOS,"A deployment and management platform for AI Agents, providing a K8s-based FastAPI runtime, metric dashboard, and on-premise availability for scalable, isolated, and secure agent integration.",1
Safety Engine,A component that ensures the safe operation of agents by detecting and preventing potential risks or errors. Safety Engines are integrated into the Upsonic Framework to provide a safety-first approach to AI development.,1
"MCP (Model, Component, Pipeline)","A modular construct that combines models, components, and pipelines to enable flexible and efficient agent development. MCPs allow for the creation of complex agents by combining reusable building blocks.",1
Graph Execution,"A mechanism for executing tasks in a graph-based architecture, allowing for complex workflows and dependencies.",1
AgentRunContext,An internal context object used to manage the execution of tasks and workflows within an agent.,1
Supervisor Agent,A central agent responsible for coordinating and managing the workflow between specialized agents in a multi-agent system.,1
Sub-Agent,"A specialized agent that performs specific tasks or operations within a larger workflow, often under the supervision of a Supervisor Agent.",1
Embedding,"A high-dimensional representation of text or other data, used to capture semantic meaning and relationships between entities. Embeddings enable agents to understand context and make informed decisions based on the meaning of input data.",1
VoltAgent,A framework for building AI agents that can perform tasks independently or collaboratively with other agents.,1
Trigger,"An event or condition that captures external input, such as a GitHub webhook or cron schedule, and initiates an agent's workflow.",1
Human-in-the-Loop Workflow,"A type of workflow that coordinates multi-step processes and allows for human input at specific points, enabling agents to make decisions that require human oversight.",1
Expense Approval Workflow,An example workflow provided by VoltAgent that demonstrates suspend/resume functionality and auto-approval or manual review based on expense amounts.,1
